import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from datetime import datetime
from utils_pdf import dataframe_to_pdf_bytes

st.set_page_config(
    page_title="Zh Scopus ‚Äî –ñ—É–±–∞–Ω–æ–≤",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Header with logo and title
col_logo, col_title = st.columns([1, 4])
with col_logo:
    st.image("assets/logo.png", use_container_width=True)
with col_title:
    st.title("Zh Scopus ‚Äî –ø–æ—Ä—Ç–∞–ª –ø—É–±–ª–∏–∫–∞—Ü–∏–π")
    st.caption("–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ñ—É–±–∞–Ω–æ–≤–∞ ‚Ä¢ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ Scopus")

@st.cache_data
def load_data(path: str, sheet: str = "ARTICLE") -> pd.DataFrame:
    df = pd.read_excel(path, sheet_name=sheet, engine="openpyxl")
    # Normalize columns
    rename_map = {
        "–ê–≤—Ç–æ—Ä (—ã)": "authors_raw",
        "Author full names": "authors_full",
        "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞": "title",
        "–ì–æ–¥": "year",
        "–ù–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞": "source",
        "–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è": "cited_by",
        "DOI": "doi",
        "–°—Å—ã–ª–∫–∞": "url",
        "ISSN": "issn",
        "–ö–≤–∞—Ä—Ç–∏–ª—å": "quartile",
        "–ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å 2024": "percentile_2024",
    }
    df = df.rename(columns=rename_map)
    # Ensure types
    if "year" in df.columns:
        df["year"] = pd.to_numeric(df["year"], errors="coerce").astype("Int64")
    if "cited_by" in df.columns:
        df["cited_by"] = pd.to_numeric(df["cited_by"], errors="coerce").fillna(0).astype(int)
    if "percentile_2024" in df.columns:
        df["percentile_2024"] = pd.to_numeric(df["percentile_2024"], errors="coerce")
    # For search: lowercase helpers
    for col in ["authors_raw", "authors_full", "title", "source"]:
        if col in df.columns:
            df[f"_{col}_lc"] = df[col].astype(str).str.lower()
    return df

df = load_data("data/zhubanov_scopus_issn.xlsx")

# ============ Sidebar Filters ============
st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã")

years = df["year"].dropna().unique()
years = np.sort(years[~pd.isna(years)])
if len(years) == 0:
    st.error("–í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≥–æ–¥–∞.")
    st.stop()

min_year, max_year = int(years.min()), int(years.max())
preset = st.sidebar.radio("–ë—ã—Å—Ç—Ä—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã", ["–í—Å–µ –≥–æ–¥—ã", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ª–µ—Ç", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ª–µ—Ç"], index=0)

if preset == "–í—Å–µ –≥–æ–¥—ã":
    year_range = st.sidebar.slider("–î–∏–∞–ø–∞–∑–æ–Ω –ª–µ—Ç", min_value=min_year, max_value=max_year,
                                   value=(min_year, max_year), step=1)
elif preset == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ª–µ—Ç":
    year_range = (max(max_year - 4, min_year), max_year)
    st.sidebar.info(f"–í—ã–±—Ä–∞–Ω–æ: {year_range[0]}‚Äì{year_range[1]}")
else:
    year_range = (max(max_year - 9, min_year), max_year)
    st.sidebar.info(f"–í—ã–±—Ä–∞–Ω–æ: {year_range[0]}‚Äì{year_range[1]}")

quartiles_all = ["Q1", "Q2", "Q3", "Q4"]
selected_quartiles = st.sidebar.multiselect("–ö–≤–∞—Ä—Ç–∏–ª—å", quartiles_all, default=quartiles_all)

percentile_range = st.sidebar.slider("–ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å 2024", min_value=0, max_value=100,
                                     value=(0, 100), step=1)

search_query = st.sidebar.text_input("–ü–æ–∏—Å–∫ (–∞–≤—Ç–æ—Ä/–Ω–∞–∑–≤–∞–Ω–∏–µ/–∏—Å—Ç–æ—á–Ω–∏–∫)", value="").strip().lower()

# ============ Filtering Logic ============
mask = pd.Series(True, index=df.index)

mask &= df["year"].between(year_range[0], year_range[1])

if "quartile" in df.columns:
    mask &= df["quartile"].astype(str).isin(selected_quartiles)

if "percentile_2024" in df.columns:
    p = df["percentile_2024"].fillna(-1)
    mask &= (p >= percentile_range[0]) & (p <= percentile_range[1])

if search_query:
    any_field = (
        df.get("_authors_raw_lc", pd.Series("", index=df.index)).str.contains(search_query, na=False) |
        df.get("_authors_full_lc", pd.Series("", index=df.index)).str.contains(search_query, na=False) |
        df.get("_title_lc", pd.Series("", index=df.index)).str.contains(search_query, na=False) |
        df.get("_source_lc", pd.Series("", index=df.index)).str.contains(search_query, na=False)
    )
    mask &= any_field

filtered = df[mask].copy()

# ============ Sorting ============
sort_column = st.sidebar.selectbox(
    "–°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ",
    options=["year", "cited_by", "percentile_2024", "quartile", "title"],
    format_func=lambda x: {
        "year": "–ì–æ–¥",
        "cited_by": "–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
        "percentile_2024": "–ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å 2024",
        "quartile": "–ö–≤–∞—Ä—Ç–∏–ª—å",
        "title": "–ù–∞–∑–≤–∞–Ω–∏–µ"
    }.get(x, x),
    index=0
)
sort_order = st.sidebar.radio("–ü–æ—Ä—è–¥–æ–∫", ["–ü–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é", "–ü–æ —É–±—ã–≤–∞–Ω–∏—é"], index=1)
ascending = (sort_order == "–ü–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é")
if sort_column in filtered.columns:
    filtered = filtered.sort_values(by=sort_column, ascending=ascending)

# ============ KPI Cards ============
k1, k2, k3, k4 = st.columns(4)
with k1:
    st.metric("–ü—É–±–ª–∏–∫–∞—Ü–∏–π", f"{len(filtered):,}".replace(",", " "))
with k2:
    st.metric("–°—É–º–º–∞—Ä–Ω—ã–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", f"{filtered['cited_by'].sum():,}".replace(",", " "))
with k3:
    avg_pct = filtered["percentile_2024"].mean() if "percentile_2024" in filtered else np.nan
    st.metric("–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å (2024)", f"{avg_pct:.1f}" if pd.notna(avg_pct) else "‚Äî")
with k4:
    top_q = filtered["quartile"].value_counts().head(1)
    st.metric("–ß–∞—â–µ –≤—Å–µ–≥–æ –∫–≤–∞—Ä—Ç–∏–ª—å", top_q.index[0] if len(top_q) > 0 else "‚Äî")

# ============ Tabs ============
tab_table, tab_cards, tab_sources, tab_authors = st.tabs(["üìä –¢–∞–±–ª–∏—Ü–∞", "üìö Scopus-–≤–∏–¥", "üèõ –¢–æ–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∏", "üë®‚Äçüíª –¢–æ–ø –∞–≤—Ç–æ—Ä—ã"])

with tab_table:
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
    show_cols = ["authors_full", "title", "year", "source", "quartile", "percentile_2024", "cited_by", "doi", "url", "issn"]
    show_cols = [c for c in show_cols if c in filtered.columns]
    st.dataframe(filtered[show_cols], use_container_width=True, height=500)

    # Export buttons
    st.markdown("### –≠–∫—Å–ø–æ—Ä—Ç")
    csv_bytes = filtered[show_cols].to_csv(index=False).encode("utf-8-sig")
    st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å CSV", csv_bytes, file_name="zh_scopus_export.csv", mime="text/csv")

    excel_buffer = BytesIO()
    with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
        filtered[show_cols].to_excel(writer, index=False, sheet_name="Export")
    st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å Excel", excel_buffer.getvalue(), file_name="zh_scopus_export.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    try:
        pdf_bytes = dataframe_to_pdf_bytes(filtered[show_cols], title="Zh Scopus ‚Äî –û—Ç—á—ë—Ç (—Ñ–∏–ª—å—Ç—Ä)")
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å PDF (–±–µ—Ç–∞)", pdf_bytes, file_name="zh_scopus_report.pdf", mime="application/pdf")
    except Exception as e:
        st.warning(f"PDF —ç–∫—Å–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

with tab_cards:
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∫–∞—Ä—Ç–æ—á–∫–∏ –≤ —Å—Ç–∏–ª–µ Scopus)")
    for _, row in filtered.iterrows():
        with st.container():
            st.markdown(f"### {row.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
            st.markdown(f"**–ê–≤—Ç–æ—Ä—ã:** {row.get('authors_full', '‚Äî')}")
            st.markdown(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** {row.get('source', '‚Äî')}")
            st.markdown(
                f"**–ì–æ–¥:** {row.get('year', '‚Äî')} | "
                f"**–ö–≤–∞—Ä—Ç–∏–ª—å:** {row.get('quartile', '‚Äî')} | "
                f"**–ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å:** {row.get('percentile_2024', '‚Äî')}"
            )
            st.markdown(f"**–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** {row.get('cited_by', 0)}")
            if pd.notna(row.get("doi", None)):
                st.markdown(f"[DOI]({row['doi']})")
            elif pd.notna(row.get("url", None)):
                st.markdown(f"[–°—Å—ã–ª–∫–∞]({row['url']})")
            st.markdown("---")

with tab_sources:
    st.subheader("–¢–æ–ø 10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ —á–∏—Å–ª—É –ø—É–±–ª–∏–∫–∞—Ü–∏–π")
    if "source" in filtered.columns:
        top_sources = (filtered.groupby("source")
                       .agg(pub_count=("title", "count"), cites=("cited_by", "sum"))
                       .sort_values("pub_count", ascending=False)
                       .head(10))
        st.bar_chart(top_sources["pub_count"])
        st.dataframe(top_sources, use_container_width=True)
    else:
        st.info("–ü–æ–ª–µ '–ù–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")

with tab_authors:
    st.subheader("–¢–æ–ø 10 –∞–≤—Ç–æ—Ä–æ–≤ –ø–æ —á–∏—Å–ª—É –ø—É–±–ª–∏–∫–∞—Ü–∏–π")
    if "authors_full" in filtered.columns:
        exploded = (filtered.assign(_authors=filtered["authors_full"].astype(str).str.split(";"))
                    .explode("_authors"))
        exploded["_authors"] = exploded["_authors"].str.strip()
        top_authors = (exploded[exploded["_authors"] != ""]
                       .groupby("_authors").agg(pub_count=("title", "count"),
                                                cites=("cited_by", "sum"))
                       .sort_values("pub_count", ascending=False).head(10))
        st.bar_chart(top_authors["pub_count"])
        st.dataframe(top_authors, use_container_width=True)
    else:
        st.info("–ü–æ–ª–µ 'Author full names' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")

st.caption("¬© Zh Scopus / –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ñ—É–±–∞–Ω–æ–≤–∞")
