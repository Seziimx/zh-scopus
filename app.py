import streamlit as st  
import pandas as pd
import numpy as np
from io import BytesIO
from utils_pdf import dataframe_to_pdf_bytes

st.set_page_config(
    page_title="Zh Scopus ‚Äî –ñ—É–±–∞–Ω–æ–≤",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)
# –í–∫–ª—é—á–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫ –≤ dataframe
st.markdown("""
    <style>
    .stDataFrame td {
        white-space: normal !important;
        word-wrap: break-word !important;
        max-width: 300px; /* –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å —à–∏—Ä–∏–Ω—É —è—á–µ–µ–∫ */
    }
    </style>
""", unsafe_allow_html=True)

# Header
col_logo, col_title = st.columns([1, 4])
with col_logo:
    st.image("assets/logo.png", use_container_width=True)
with col_title:
    st.title("Zh Scopus ‚Äî –ø–æ—Ä—Ç–∞–ª –ø—É–±–ª–∏–∫–∞—Ü–∏–π")
    st.caption("–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ñ—É–±–∞–Ω–æ–≤–∞ ‚Ä¢ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ Scopus")

# ================= DATA ==================
@st.cache_data
def load_data(path: str, sheet: str = "ARTICLE") -> pd.DataFrame:
    df = pd.read_excel(path, sheet_name=sheet, engine="openpyxl")
    rename_map = {
        "–ê–≤—Ç–æ—Ä (—ã)": "authors_raw",
        "Author full names": "authors_full",
        "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞": "title",
        "–ì–æ–¥": "year",
        "–ù–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞": "source",
        "–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è": "cited_by",
        "DOI": "doi",
        "–°—Å—ã–ª–∫–∞": "url",
        "ISSN": "issn",
        "–ö–≤–∞—Ä—Ç–∏–ª—å": "quartile",
        "–ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å 2024": "percentile_2024",
    }
    df = df.rename(columns=rename_map)

    # types
    df["year"] = pd.to_numeric(df.get("year"), errors="coerce").astype("Int64")
    df["cited_by"] = pd.to_numeric(df.get("cited_by"), errors="coerce").fillna(0).astype(int)
    df["percentile_2024"] = pd.to_numeric(df.get("percentile_2024"), errors="coerce")

    # DOI link
    df["doi_link"] = df.get("doi").apply(
        lambda x: f"https://doi.org/{x.strip()}" if pd.notna(x) and str(x).strip() else None
    )

    # lowercase helpers
    for col in ["authors_full", "title", "source"]:
        if col in df.columns:
            df[f"_{col}_lc"] = df[col].astype(str).str.lower()

    return df

df = load_data("data/zhubanov_scopus_issn.xlsx")

# ================= SIDEBAR ==================
st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã")

# –ì–æ–¥—ã
years = df["year"].dropna().unique()
years = np.sort(years)
min_year, max_year = int(years.min()), int(years.max())

preset = st.sidebar.radio("–ò–Ω—Ç–µ—Ä–≤–∞–ª", ["–í—Å–µ –≥–æ–¥—ã", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ª–µ—Ç", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ª–µ—Ç"], index=0)
if preset == "–í—Å–µ –≥–æ–¥—ã":
    year_range = st.sidebar.slider("–î–∏–∞–ø–∞–∑–æ–Ω –ª–µ—Ç", min_value=min_year, max_value=max_year,
                                   value=(min_year, max_year), step=1)
elif preset == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ª–µ—Ç":
    year_range = (max(max_year - 4, min_year), max_year)
else:
    year_range = (max(max_year - 9, min_year), max_year)

# –ò—Å—Ç–æ—á–Ω–∏–∫–∏
st.sidebar.markdown("### –§–∏–ª—å—Ç—Ä –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º")
source_counts = df["source"].value_counts()
selected_sources = st.sidebar.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏",
    options=source_counts.index.tolist(),
    format_func=lambda x: f"{x} ({source_counts[x]})"
)

# –ê–≤—Ç–æ—Ä—ã
st.sidebar.markdown("### –§–∏–ª—å—Ç—Ä –ø–æ –∞–≤—Ç–æ—Ä–∞–º")
author_counts = (df["authors_full"].astype(str)
                 .str.split(";").explode().str.strip().value_counts())
selected_authors = st.sidebar.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∞–≤—Ç–æ—Ä–æ–≤",
    options=author_counts.index.tolist(),
    format_func=lambda x: f"{x} ({author_counts[x]})"
)

# –ö–≤–∞—Ä—Ç–∏–ª—å –∏ –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å
quartiles_all = ["Q1", "Q2", "Q3", "Q4"]
selected_quartiles = st.sidebar.multiselect("–ö–≤–∞—Ä—Ç–∏–ª—å", quartiles_all, default=quartiles_all)
percentile_range = st.sidebar.slider("–ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å 2024", 0, 100, (0, 100), step=1)

# –ü–æ–∏—Å–∫
search_query = st.sidebar.text_input("–ü–æ–∏—Å–∫ (–∞–≤—Ç–æ—Ä/–Ω–∞–∑–≤–∞–Ω–∏–µ/–∏—Å—Ç–æ—á–Ω–∏–∫)").strip().lower()

# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
sort_option = st.sidebar.selectbox(
    "–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞",
    [
        "–î–∞—Ç–∞ (–Ω–æ–≤—ã–µ ‚Üí —Å—Ç–∞—Ä—ã–µ)",
        "–î–∞—Ç–∞ (—Å—Ç–∞—Ä—ã–µ ‚Üí –Ω–æ–≤—ã–µ)",
        "–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–º–Ω–æ–≥–æ ‚Üí –º–∞–ª–æ)",
        "–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–º–∞–ª–æ ‚Üí –º–Ω–æ–≥–æ)",
        "–ê–≤—Ç–æ—Ä (A‚ÄìZ)",
        "–ê–≤—Ç–æ—Ä (Z‚ÄìA)",
        "–ò—Å—Ç–æ—á–Ω–∏–∫ (A‚ÄìZ)",
        "–ò—Å—Ç–æ—á–Ω–∏–∫ (Z‚ÄìA)",
    ],
    index=0
)

# ================= FILTERING ==================
mask = df["year"].between(year_range[0], year_range[1])

if selected_sources:
    mask &= df["source"].isin(selected_sources)

if selected_authors:
    mask &= df["authors_full"].astype(str).apply(
        lambda x: any(a in x for a in selected_authors)
    )

mask &= df["quartile"].astype(str).isin(selected_quartiles)
mask &= df["percentile_2024"].fillna(-1).between(percentile_range[0], percentile_range[1])

if search_query:
    mask &= (
        df["_authors_full_lc"].str.contains(search_query, na=False) |
        df["_title_lc"].str.contains(search_query, na=False) |
        df["_source_lc"].str.contains(search_query, na=False)
    )

filtered = df[mask].copy()

# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
if sort_option == "–î–∞—Ç–∞ (–Ω–æ–≤—ã–µ ‚Üí —Å—Ç–∞—Ä—ã–µ)":
    filtered = filtered.sort_values("year", ascending=False)
elif sort_option == "–î–∞—Ç–∞ (—Å—Ç–∞—Ä—ã–µ ‚Üí –Ω–æ–≤—ã–µ)":
    filtered = filtered.sort_values("year", ascending=True)
elif sort_option == "–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–º–Ω–æ–≥–æ ‚Üí –º–∞–ª–æ)":
    filtered = filtered.sort_values("cited_by", ascending=False)
elif sort_option == "–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–º–∞–ª–æ ‚Üí –º–Ω–æ–≥–æ)":
    filtered = filtered.sort_values("cited_by", ascending=True)
elif sort_option == "–ê–≤—Ç–æ—Ä (A‚ÄìZ)":
    filtered = filtered.sort_values("authors_full", ascending=True)
elif sort_option == "–ê–≤—Ç–æ—Ä (Z‚ÄìA)":
    filtered = filtered.sort_values("authors_full", ascending=False)
elif sort_option == "–ò—Å—Ç–æ—á–Ω–∏–∫ (A‚ÄìZ)":
    filtered = filtered.sort_values("source", ascending=True)
elif sort_option == "–ò—Å—Ç–æ—á–Ω–∏–∫ (Z‚ÄìA)":
    filtered = filtered.sort_values("source", ascending=False)

# ================= KPI ==================
k1, k2, k3, k4 = st.columns(4)
with k1:
    st.metric("–ü—É–±–ª–∏–∫–∞—Ü–∏–π", f"{len(filtered):,}".replace(",", " "))
with k2:
    st.metric("–°—É–º–º–∞—Ä–Ω—ã–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", f"{filtered['cited_by'].sum():,}".replace(",", " "))
with k3:
    avg_pct = filtered["percentile_2024"].mean()
    st.metric("–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å (2024)", f"{avg_pct:.1f}" if pd.notna(avg_pct) else "‚Äî")
with k4:
    top_q = filtered["quartile"].value_counts().head(1)
    st.metric("–ß–∞—â–µ –≤—Å–µ–≥–æ –∫–≤–∞—Ä—Ç–∏–ª—å", top_q.index[0] if len(top_q) > 0 else "‚Äî")

# ================= TABS ==================
tab_table, tab_cards, tab_sources, tab_authors = st.tabs(
    ["üìä –¢–∞–±–ª–∏—Ü–∞", "üìö Scopus-–≤–∏–¥", "üèõ –¢–æ–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∏", "üë®‚Äçüíª –¢–æ–ø –∞–≤—Ç–æ—Ä—ã"]
)

with tab_table:
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")

    filtered_display = filtered.copy().reset_index(drop=True)
    filtered_display.index = filtered_display.index + 1
    filtered_display.insert(0, "‚Ññ", filtered_display.index)

    # –ê–≤—Ç–æ—Ä—ã: –∑–∞–º–µ–Ω—è–µ–º ";" –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
    if "authors_raw" in filtered_display.columns:
        filtered_display["authors_fmt"] = (
            filtered_display["authors_raw"]
            .astype(str)
            .str.replace(";", "\n")
        )
    else:
        filtered_display["authors_fmt"] = "‚Äî"

    show_cols = ["‚Ññ", "authors_fmt", "title", "year", "source",
                 "quartile", "percentile_2024", "cited_by",
                 "doi_link", "url", "issn"]
    show_cols = [c for c in show_cols if c in filtered_display.columns]

    st.dataframe(filtered_display[show_cols], use_container_width=True, height=500)






    # –≠–∫—Å–ø–æ—Ä—Ç
    st.markdown("### –≠–∫—Å–ø–æ—Ä—Ç")

    export_cols = [c for c in show_cols if c in filtered_display.columns]

    csv_bytes = filtered_display[export_cols].to_csv(index=False).encode("utf-8-sig")
    st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å CSV", csv_bytes, file_name="zh_scopus_export.csv", mime="text/csv")

    excel_buffer = BytesIO()
    with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
        filtered_display[export_cols].to_excel(writer, index=False, sheet_name="Export")
    st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å Excel", excel_buffer.getvalue(), file_name="zh_scopus_export.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    try:
        pdf_bytes = dataframe_to_pdf_bytes(filtered_display[export_cols], title="Zh Scopus ‚Äî –û—Ç—á—ë—Ç (—Ñ–∏–ª—å—Ç—Ä)")
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å PDF (–±–µ—Ç–∞)", pdf_bytes, file_name="zh_scopus_report.pdf", mime="application/pdf")
    except Exception as e:
        st.warning(f"PDF —ç–∫—Å–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

with tab_cards:
    st.subheader("–ü—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ —Å—Ç–∏–ª–µ Scopus")

    for idx, row in enumerate(filtered.itertuples(), start=1):
        with st.container():
            st.markdown(f"### {idx}. {getattr(row, 'title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
            
            # –ê–≤—Ç–æ—Ä—ã –∏–∑ "authors_raw", —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
            authors_fmt = str(getattr(row, "authors_raw", "‚Äî")).replace(";", "\n")
            st.markdown(f"**–ê–≤—Ç–æ—Ä—ã:**\n{authors_fmt}")
            
            st.markdown(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** {getattr(row, 'source', '‚Äî')}")
            st.markdown(
                f"**–ì–æ–¥:** {getattr(row, 'year', '‚Äî')} | "
                f"**–ö–≤–∞—Ä—Ç–∏–ª—å:** {getattr(row, 'quartile', '‚Äî')} | "
                f"**–ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å:** {getattr(row, 'percentile_2024', '‚Äî')}"
            )
            st.markdown(f"**–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** {getattr(row, 'cited_by', 0)}")

            # üîπ –°—Å—ã–ª–∫–∏
            links = []
            if pd.notna(getattr(row, "doi_link", None)):
                links.append(f"[DOI]({row.doi_link})")
            if pd.notna(getattr(row, "url", None)):
                links.append(f"[Scopus —Å—Å—ã–ª–∫–∞]({row.url})")
            if links:
                st.markdown(" | ".join(links))

            st.markdown("---")



with tab_sources:
    st.subheader("–¢–æ–ø –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
    top_sources = (filtered.groupby("source")
                   .agg(pub_count=("title", "count"), cites=("cited_by", "sum"))
                   .sort_values("pub_count", ascending=False)
                   .head(20))
    st.bar_chart(top_sources["pub_count"])
    st.dataframe(top_sources, use_container_width=True)

with tab_authors:
    st.subheader("–¢–æ–ø –∞–≤—Ç–æ—Ä–æ–≤")
    exploded = (filtered.assign(_authors=filtered["authors_full"].astype(str).str.split(";"))
                .explode("_authors"))
    exploded["_authors"] = exploded["_authors"].str.strip()
    top_authors = (exploded[exploded["_authors"] != ""]
                   .groupby("_authors").agg(pub_count=("title", "count"),
                                            cites=("cited_by", "sum"))
                   .sort_values("pub_count", ascending=False).head(20))
    st.bar_chart(top_authors["pub_count"])
    st.dataframe(top_authors, use_container_width=True)

st.caption("¬© Zh Scopus / –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ñ—É–±–∞–Ω–æ–≤–∞")
